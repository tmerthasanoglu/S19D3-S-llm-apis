{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf93d81e",
   "metadata": {},
   "source": [
    "# Gemini ve LangChain ile LLM API'larÄ±nÄ± Ã‡aÄŸÄ±rma GiriÅŸ ğŸ¦œğŸ”—\n",
    "\n",
    "Bu notebook'ta LangChain aracÄ±lÄ±ÄŸÄ±yla LLM API'larÄ±nÄ± nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz. Ã–rnek olarak Google'Ä±n Gemini API'sÄ±nÄ± kullanacaÄŸÄ±z. Bu notebook'un sonunda, LangChain kullanarak API Ã§aÄŸrÄ±larÄ± yapmayÄ± ve bunu neden yaptÄ±ÄŸÄ±mÄ±zÄ± bileceksiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27145cf",
   "metadata": {},
   "source": [
    "## âš™ï¸ Kurulum\n",
    "\n",
    "ğŸ‘‰ Kurulum aÅŸamasÄ±nda oluÅŸturduÄŸumuz `.env` dosyasÄ±ndaki ortam deÄŸiÅŸkenlerini yÃ¼klemek iÃ§in aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5d7b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:57:16.345715Z",
     "iopub.status.busy": "2026-02-03T09:57:16.343861Z",
     "iopub.status.idle": "2026-02-03T09:57:16.400741Z",
     "shell.execute_reply": "2026-02-03T09:57:16.398712Z",
     "shell.execute_reply.started": "2026-02-03T09:57:16.345626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf63ce",
   "metadata": {},
   "source": [
    "ğŸ‘‰ HÃ¼crenin Ã§Ä±ktÄ±sÄ± \"`True`\" mu? Harika! ArtÄ±k Gemini API ile kimlik doÄŸrulamasÄ± yapmak iÃ§in kullanÄ±lacak bir `GOOGLE_API_KEY` ortam deÄŸiÅŸkeni kurmuÅŸ olduk.\n",
    "\n",
    "EÄŸer deÄŸilse, yardÄ±m isteyin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b898bb",
   "metadata": {},
   "source": [
    "## Basit Bir API Ã‡aÄŸrÄ±sÄ± Yapma\n",
    "\n",
    "Bu notebook'ta ÅŸunlarÄ±n nasÄ±l yapÄ±lacaÄŸÄ±nÄ± gÃ¶stereceÄŸiz:\n",
    "1. Google'Ä±n kendi kÃ¼tÃ¼phanesini kullanarak API Ã§aÄŸrÄ±sÄ± yapma.\n",
    "2. AynÄ± iÅŸlemi LangChain kullanarak yapma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8faa4",
   "metadata": {},
   "source": [
    "## Google Generative AI KÃ¼tÃ¼phanesini Kullanma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8a0df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:57:35.590153Z",
     "iopub.status.busy": "2026-02-03T09:57:35.589115Z",
     "iopub.status.idle": "2026-02-03T09:57:39.085469Z",
     "shell.execute_reply": "2026-02-03T09:57:39.083951Z",
     "shell.execute_reply.started": "2026-02-03T09:57:35.590104Z"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934eef38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:57:40.754531Z",
     "iopub.status.busy": "2026-02-03T09:57:40.753441Z",
     "iopub.status.idle": "2026-02-03T09:57:45.112849Z",
     "shell.execute_reply": "2026-02-03T09:57:45.111423Z",
     "shell.execute_reply.started": "2026-02-03T09:57:40.754484Z"
    }
   },
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"What is the capital of France?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89625d00",
   "metadata": {},
   "source": [
    "`response` nesnesine bir gÃ¶z atalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d857a84c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:57:47.061792Z",
     "iopub.status.busy": "2026-02-03T09:57:47.060862Z",
     "iopub.status.idle": "2026-02-03T09:57:47.074039Z",
     "shell.execute_reply": "2026-02-03T09:57:47.072139Z",
     "shell.execute_reply.started": "2026-02-03T09:57:47.061738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd47ed0",
   "metadata": {},
   "source": [
    "GerÃ§ek cevabÄ± nasÄ±l alabileceÄŸinizi gÃ¶rÃ¼yor musunuz?\n",
    "\n",
    "Neyse ki, cevabÄ± hemen almak iÃ§in sadece `.text` Ã¶zelliÄŸini kullanabiliriz. Deneyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95947ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:58:00.748462Z",
     "iopub.status.busy": "2026-02-03T09:58:00.747185Z",
     "iopub.status.idle": "2026-02-03T09:58:00.762160Z",
     "shell.execute_reply": "2026-02-03T09:58:00.760414Z",
     "shell.execute_reply.started": "2026-02-03T09:58:00.748318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaca4e2",
   "metadata": {},
   "source": [
    "Gemini cevaplarÄ±nÄ± Markdown formatÄ±nda dÃ¶ndÃ¼rÃ¼r. Bunu kullanalÄ±m!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84cf44c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:58:07.174543Z",
     "iopub.status.busy": "2026-02-03T09:58:07.173206Z",
     "iopub.status.idle": "2026-02-03T09:58:07.185012Z",
     "shell.execute_reply": "2026-02-03T09:58:07.182958Z",
     "shell.execute_reply.started": "2026-02-03T09:58:07.174494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is **Paris**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c6bd7",
   "metadata": {},
   "source": [
    "OluÅŸturma parametrelerini de deÄŸiÅŸtirebilirsiniz. `google.genai` kullanarak bunu ÅŸu ÅŸekilde yaparsÄ±nÄ±z:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980cb0cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:58:12.872336Z",
     "iopub.status.busy": "2026-02-03T09:58:12.870977Z",
     "iopub.status.idle": "2026-02-03T09:58:15.747740Z",
     "shell.execute_reply": "2026-02-03T09:58:15.745991Z",
     "shell.execute_reply.started": "2026-02-03T09:58:12.872287Z"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types # We need to import types for the config\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"Write a social media post about how much you're learning about transformers.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=200,\n",
    "        temperature=1.0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "736666b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T09:58:16.862393Z",
     "iopub.status.busy": "2026-02-03T09:58:16.861210Z",
     "iopub.status.idle": "2026-02-03T09:58:16.873990Z",
     "shell.execute_reply": "2026-02-03T09:58:16.871879Z",
     "shell.execute_reply.started": "2026-02-03T09:58:16.862350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are a few options for a social media post about learning transformers, choose the one that best fits your style!\n",
       "\n",
       "**Option 1: Enthusiastic & Simple**\n",
       "\n",
       "> My brain is officially a transformer enthusiast! ğŸ§ âœ¨ So much to learn in the world of deep learning and these models are truly mind-blowing. Every day is a new \"aha!\" moment. #DeepLearning #Transformers #AI #MachineLearning #Learning\n",
       "\n",
       "**Option 2: Slightly More Technical & Curious**\n",
       "\n",
       "> Diving deep into the architecture of transformers and honestly, I'm fascinated! The attention mechanism alone is a game-changer. So much to explore and understand. Anyone else obsessed with these models right now? ğŸ‘‡ #AI #MachineLearning #Transformers #NLP #DeepLearningJourney\n",
       "\n",
       "**Option 3: Humorous & Relatable**\n",
       "\n",
       "> My brain is currently running on a transformer model... and it's taking *a lot* of attention to process everything! ğŸ˜‚ Seriously though,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd999ae",
   "metadata": {},
   "source": [
    "Harika. Ancak baÅŸka bir API denemek istediÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n, Ã¶rneÄŸin OpenAI'nin veya Anthropic'in?\n",
    "\n",
    "OnlarÄ±n dokÃ¼mantasyonlarÄ±nÄ± incelemek ve tÃ¼m kodunuzu onlarÄ±n API'sini kullanacak ÅŸekilde yeniden yazmak zorunda kalÄ±rsÄ±nÄ±z. Tabii ki benzer olacaktÄ±r, ancak aynÄ± olmayacaktÄ±r.\n",
    "\n",
    "Neyse ki LangChain var!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487e75a",
   "metadata": {},
   "source": [
    "## LangChain Kullanma ğŸ¦œğŸ”—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f012972",
   "metadata": {},
   "source": [
    "Neden LangChain kullanÄ±rsÄ±nÄ±z?\n",
    "\n",
    "1. **Model-BaÄŸÄ±msÄ±z Kod**\n",
    "\n",
    "   LangChain, farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± (Google, OpenAI, Anthropic, vb.) arasÄ±nda minimal kod deÄŸiÅŸikliÄŸi ile geÃ§iÅŸ yapmanÄ±zÄ± saÄŸlayan soyutlamalar sunar. Google API'sine doÄŸrudan kod yazarsanÄ±z, saÄŸlayÄ±cÄ± deÄŸiÅŸtirmek Ã¶nemli Ã¶lÃ§Ã¼de yeniden dÃ¼zenleme gerektirir.\n",
    "\n",
    "2. **BirleÅŸik ArayÃ¼z**\n",
    "\n",
    "   LangChain, altta yatan API'den baÄŸÄ±msÄ±z olarak farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± arasÄ±nda etkileÅŸimleri standartlaÅŸtÄ±rÄ±r ve tutarlÄ± yÃ¶ntemler ile yanÄ±t formatlarÄ± sunar.\n",
    "\n",
    "3. **BileÅŸenlerle Ã‡alÄ±ÅŸabilirlik**\n",
    "\n",
    "   LangChain'in zincir ve pipeline mimarisi, tÃ¼m alt yapÄ±yÄ± kendiniz halletmeden prompt, bellek ve eriÅŸim sistemlerini birleÅŸtiren karmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ± oluÅŸturmayÄ± kolaylaÅŸtÄ±rÄ±r.\n",
    "\n",
    "4. **YerleÅŸik AraÃ§lar**\n",
    "\n",
    "   LangChain, Ã§Ä±ktÄ± ayrÄ±ÅŸtÄ±rma, prompt ÅŸablonlarÄ± ve kendiniz uygulamanÄ±z gereken diÄŸer yardÄ±mcÄ± araÃ§larÄ± iÃ§erir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2fb86",
   "metadata": {},
   "source": [
    "[LangChain'in chat entegrasyonlarÄ± listesi](https://docs.langchain.com/oss/python/integrations/chat)'ne gidin ve entegrasyon listesine bakÄ±n. Favori LLM saÄŸlayÄ±cÄ±nÄ±zÄ± bulabiliyor musunuz?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed6bb0",
   "metadata": {},
   "source": [
    "Kodumuzda `chat_models.ChatGoogleGenerativeAI` kullanmak istemiyoruz Ã§Ã¼nkÃ¼ bu Ã¶zellikle Gemini iÃ§in yapÄ±lmÄ±ÅŸ. LLM'yi deÄŸiÅŸtirmek istersek, modeli baÅŸlatma ÅŸeklimizi deÄŸiÅŸtirmek zorunda kalÄ±rÄ±z. Neyse ki LangChain bir modeli baÅŸlatmak iÃ§in daha genel bir yol sunar.\n",
    "\n",
    "Gemini'yi tekrar kullanalÄ±m, ancak ÅŸimdi LangChain'in genel Chat Models'ini kullanarak.\n",
    "\n",
    "ğŸ‘‰ [LangChain'in \"Models\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/models) sayfasÄ±na gidin ve Gemini kullanarak bir chat modelinin nasÄ±l baÅŸlatÄ±lacaÄŸÄ±nÄ± bulun.\n",
    "\n",
    "Ä°puÃ§larÄ±:\n",
    "1. Hemen \"Basic Usage\" bÃ¶lÃ¼mÃ¼ne gidin.\n",
    "2. Kullanmak istediÄŸiniz modeli seÃ§erek doÄŸru dokÃ¼mantasyonu hemen gÃ¶rebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd651fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:01:42.371403Z",
     "iopub.status.busy": "2026-02-03T10:01:42.370370Z",
     "iopub.status.idle": "2026-02-03T10:01:43.891276Z",
     "shell.execute_reply": "2026-02-03T10:01:43.889611Z",
     "shell.execute_reply.started": "2026-02-03T10:01:42.371352Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash-lite\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1aed65",
   "metadata": {},
   "source": [
    "Modelin en temel kullanÄ±mÄ± sadece `.invoke()` metodunu kullanmaktÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f96cd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:02:44.099340Z",
     "iopub.status.busy": "2026-02-03T10:02:44.098266Z",
     "iopub.status.idle": "2026-02-03T10:02:46.427959Z",
     "shell.execute_reply": "2026-02-03T10:02:46.426409Z",
     "shell.execute_reply.started": "2026-02-03T10:02:44.099282Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "response=model.invoke(\"What is the capital of Turkiye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877aa57",
   "metadata": {},
   "source": [
    "YanÄ±ta bir gÃ¶z atalÄ±m. Nesnenin tÃ¼m Ã¶znitelik ve metodlarÄ±nÄ± iÃ§eren `__dict__`'ini gÃ¼zel ÅŸekilde yazdÄ±rmak iÃ§in `pprint()` kullanÄ±yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f9430d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:02:53.892480Z",
     "iopub.status.busy": "2026-02-03T10:02:53.891440Z",
     "iopub.status.idle": "2026-02-03T10:02:53.902438Z",
     "shell.execute_reply": "2026-02-03T10:02:53.900827Z",
     "shell.execute_reply.started": "2026-02-03T10:02:53.892429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_kwargs': {},\n",
      " 'content': 'The capital of Turkiye is **Ankara**.',\n",
      " 'id': 'lc_run--019c22f4-5606-7e40-9165-9c82d0b0b185-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'STOP',\n",
      "                       'model_name': 'gemini-2.5-flash-lite',\n",
      "                       'model_provider': 'google_genai',\n",
      "                       'safety_ratings': []},\n",
      " 'tool_calls': [],\n",
      " 'type': 'ai',\n",
      " 'usage_metadata': {'input_token_details': {'cache_read': 0},\n",
      "                    'input_tokens': 7,\n",
      "                    'output_tokens': 10,\n",
      "                    'total_tokens': 17}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8482a87",
   "metadata": {},
   "source": [
    "CevabÄ± Ã§Ä±karÄ±n ve gÃ¶rÃ¼ntÃ¼leyin. Markdown formatÄ±nda olduÄŸunu unutmayÄ±n, bu yÃ¼zden gÃ¼zel gÃ¶rÃ¼nmesini saÄŸlayabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434e6367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:03:28.525554Z",
     "iopub.status.busy": "2026-02-03T10:03:28.524225Z",
     "iopub.status.idle": "2026-02-03T10:03:28.538312Z",
     "shell.execute_reply": "2026-02-03T10:03:28.536477Z",
     "shell.execute_reply.started": "2026-02-03T10:03:28.525505Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of Turkiye is **Ankara**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4584d",
   "metadata": {},
   "source": [
    "Modelin temperature deÄŸerini `.temperature` Ã¶zniteliÄŸine eriÅŸerek kontrol edebilirsiniz. Deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7123f54b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:04:35.042326Z",
     "iopub.status.busy": "2026-02-03T10:04:35.040766Z",
     "iopub.status.idle": "2026-02-03T10:04:35.053088Z",
     "shell.execute_reply": "2026-02-03T10:04:35.051458Z",
     "shell.execute_reply.started": "2026-02-03T10:04:35.042279Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.temperature,model.max_output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b877d6",
   "metadata": {},
   "source": [
    "Modeli kullanmadan Ã¶nce, Ã¶zniteliklere yeni deÄŸerler atayarak oluÅŸturma parametrelerini de ayarlayabiliriz.\n",
    "\n",
    "Daha Ã¶nce Google'Ä±n kÃ¼tÃ¼phanesini kullanarak sosyal medya gÃ¶nderisi yazmak iÃ§in yaptÄ±ÄŸÄ±mÄ±zÄ±n eÅŸdeÄŸerini kodlamaya Ã§alÄ±ÅŸÄ±n.\n",
    "\n",
    "> _Not_: Normal olarak modelin `max_output_tokens` deÄŸerini ayarlayabilmemiz gerekir (modeli baÅŸlatÄ±rken veya daha sonra Ã¶zniteliÄŸi deÄŸiÅŸtirerek). _langchain_google_genai_'nin mevcut sÃ¼rÃ¼mÃ¼ (4.1.1) bir [hataya](https://github.com/langchain-ai/langchain-google/issues/1454) sahip ve bu Ã§alÄ±ÅŸmÄ±yor. GeÃ§ici Ã§Ã¶zÃ¼m? `max_output_tokens`'Ä± `.invoke()` metodunun bir parametresi olarak ayarlayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26691672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:06:37.029792Z",
     "iopub.status.busy": "2026-02-03T10:06:37.028948Z",
     "iopub.status.idle": "2026-02-03T10:06:39.134056Z",
     "shell.execute_reply": "2026-02-03T10:06:39.132197Z",
     "shell.execute_reply.started": "2026-02-03T10:06:37.029749Z"
    },
    "tags": [
     "steps"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are a few options for a social media post about learning Transformers, ranging in tone and detail:\n",
       "\n",
       "**Option 1: Enthusiastic & Brief**\n",
       "\n",
       "ğŸ¤¯ My brain is buzzing with all things Transformers! From attention mechanisms to multi-head attention, I'm diving deep into this incredible architecture. So much to learn, so little time! #Transformers #MachineLearning #DeepLearning #AI\n",
       "\n",
       "**Option 2: Slightly More Detailed & Curious**\n",
       "\n",
       "Been spending a lot of time lately exploring the world of Transformers, and WOW! ğŸ¤© It's amazing how this architecture has revolutionized NLP and is now making waves everywhere else. Still wrapping my head around the intricacies of self-attention and positional encoding, but loving every minute of it. What are your favorite Transformer resources? #AIResearch #NLP #NeuralNetworks #Learning\n",
       "\n",
       "**Option 3: Focused on a Specific Aspect**\n",
       "\n",
       "Just had a breakthrough moment understanding the power of self-attention in Transformers! âœ¨ It's truly mind-bending how these models can weigh the importance of different input tokens. Officially hooked on this deep dive! #TransformerArchitecture #AttentionIsAllYouNeed #MachineLearningEngineer #Tech\n",
       "\n",
       "**Option 4: A Bit More Personal & Humorous**\n",
       "\n",
       "My coffee intake has doubled, and my mind is officially a Transformer fan club. ğŸ¤– Seriously though, the learning curve is steep but so rewarding. Every new concept unlocked feels like a win! Send more brain fuel! ğŸ§ âš¡ï¸ #AIEducation #TransformerModels #TechJourney #NeverStopLearning\n",
       "\n",
       "**Option 5: Short & Sweet**\n",
       "\n",
       "Transformers are opening my eyes to a whole new world of AI! ğŸŒ So much to absorb, so much potential. #AI #MachineLearning #Transformers\n",
       "\n",
       "**Remember to consider:**\n",
       "\n",
       "*   **Your audience:** Who are you trying to reach? (Fellow developers, AI enthusiasts, friends?)\n",
       "*   **Your platform:** Twitter might favor shorter posts, while LinkedIn could handle more detail.\n",
       "*   **Visuals:** Consider adding a relevant image or GIF (e.g., a Transformer model diagram, a robot emoji, a brain emoji).\n",
       "\n",
       "Choose the option that best suits your style and the message you want to convey! Good luck with your Transformer learning journey!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the maximum number of output tokens to 200\n",
    "\n",
    "model.max_output_tokens=200\n",
    "\n",
    "# Set the temperature to 1.0\n",
    "\n",
    "model.temperature=1.0\n",
    "\n",
    "# Generate a response with the new settings\n",
    "\n",
    "response = model.invoke(\"Write a social media post about how much you're learning about transformers.\")\n",
    "\n",
    "# Display the response\n",
    "\n",
    "Markdown(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2bc5b8",
   "metadata": {},
   "source": [
    "Bunun avantajÄ±? Bu LangChain Chat Model birÃ§ok baÅŸka API'yi destekleyebilir.\n",
    "\n",
    "BaÅŸka bir modele geÃ§mek iÃ§in deÄŸiÅŸtirmeniz gereken tek ÅŸeyler:\n",
    "1. DiÄŸer model iÃ§in bir API anahtarÄ± alÄ±n ve kodunuzda tanÄ±mlayÄ±n.\n",
    "2. Modeli baÅŸlatÄ±rken model ve saÄŸlayÄ±cÄ±yÄ± deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9504fa69",
   "metadata": {},
   "source": [
    "### Ã‡oklu Mesajlar\n",
    "\n",
    "`.invoke()` fonksiyonunu sadece tek bir mesajla kullanmak biraz kÄ±sÄ±tlayÄ±cÄ±.\n",
    "\n",
    "Åu gibi birden fazla mesaj saÄŸlayabilirsiniz:\n",
    "- `SystemMessage` veya sistem mesajlarÄ±: modelin nasÄ±l davranacaÄŸÄ±nÄ± sÃ¶ylemek iÃ§in\n",
    "- `HumanMessage` veya KullanÄ±cÄ± mesajlarÄ±: kullanÄ±cÄ±dan gelen girdi\n",
    "- `AIMessage` veya Asistan mesajlarÄ±: modelden gelen yanÄ±t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000f5fb",
   "metadata": {},
   "source": [
    "Bir sosyal medya yazarÄ± yapalÄ±m.\n",
    "\n",
    "Modele nasÄ±l davranacaÄŸÄ±nÄ± aÃ§Ä±klayan bir sistem mesajÄ± gÃ¶ndereceÄŸiz. Sonra kullanÄ±cÄ± mesajÄ±nda, kendimizi sadece yazacaÄŸÄ± konuyu vermekle sÄ±nÄ±rlayabiliriz.\n",
    "\n",
    "Bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenmek iÃ§in [LangChain'in \"Messages\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/messages)'na bakÄ±n.\n",
    "\n",
    "Sistem mesajÄ± iÃ§in ilhama mÄ± ihtiyacÄ±nÄ±z var? Ä°ÅŸte baÅŸlamanÄ±z iÃ§in temel bir talimat:\n",
    "\n",
    "```python\n",
    "\"\"\"Sen Ãœretken AI Ã¶ÄŸrencisi iÃ§in gÃ¶nderiler yazan yaratÄ±cÄ± bir sosyal medya yazarÄ±sÄ±n.\n",
    "GÃ¶nderilerinde her zaman kelime oyunu ve harekete geÃ§irici Ã§aÄŸrÄ± bulunur.\n",
    "GÃ¶nderilerin maksimum 200 karakter uzunluÄŸundadÄ±r.\n",
    "Her zaman emoji kullanÄ±rsÄ±n.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68e41111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T10:11:32.748584Z",
     "iopub.status.busy": "2026-02-03T10:11:32.747566Z",
     "iopub.status.idle": "2026-02-03T10:11:33.988177Z",
     "shell.execute_reply": "2026-02-03T10:11:33.986594Z",
     "shell.execute_reply.started": "2026-02-03T10:11:32.748533Z"
    },
    "tags": [
     "steps"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Bir transformers Ã¶ÄŸrencisi mi? Harika bir yolculuk! ğŸ¤– Hem \"dÃ¶nÃ¼ÅŸÃ¼mler\" hem de \"Ã¶ÄŸrenmeler\"le dolu bir macera! âœ¨ Daha fazlasÄ±nÄ± Ã¶ÄŸrenmek iÃ§in hemen baÅŸla! #Transformers #Ã–ÄŸrenme #Teknoloji ğŸš€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary classes\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Create a list of messages\n",
    "\n",
    "msn=[\n",
    "    SystemMessage(\"\"\"Sen Ãœretken AI Ã¶ÄŸrencisi iÃ§in gÃ¶nderiler yazan yaratÄ±cÄ± bir sosyal medya yazarÄ±sÄ±n.\n",
    "GÃ¶nderilerinde her zaman kelime oyunu ve harekete geÃ§irici Ã§aÄŸrÄ± bulunur.\n",
    "GÃ¶nderilerin maksimum 200 karakter uzunluÄŸundadÄ±r.\n",
    "Her zaman emoji kullanÄ±rsÄ±n.\n",
    "\"\"\"),\n",
    "    HumanMessage(\"Transformers lari Ogreniyorum.\")]\n",
    "\n",
    "# Generate a response using the list of messages\n",
    "\n",
    "response=model.invoke(msn)\n",
    "\n",
    "# Display the response\n",
    "\n",
    "Markdown(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55da53a",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! ArtÄ±k LangChain kullanarak Ã§oklu mesajlarla temel prompt yazma konusunda uzmanlaÅŸtÄ±nÄ±z."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
